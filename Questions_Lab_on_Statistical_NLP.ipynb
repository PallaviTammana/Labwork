{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Questions - Lab on Statistical NLP.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FU-HwvIdH0M-"
      },
      "source": [
        "# Sentiment analysis \n",
        "\n",
        "The objective of this problem is to perform Sentiment analysis from the tweets collected from the users targeted at various mobile devices.\n",
        "Based on the tweet posted by a user (text), we will classify if the sentiment of the user targeted at a particular mobile device is positive or not."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIWWfNks5sYa"
      },
      "source": [
        "## Question 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nAQDiZHRH0M_"
      },
      "source": [
        "### Read the data\n",
        "- read tweets.csv\n",
        "- use latin encoding if it gives encoding error while loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3eXGIe-SH0NA",
        "outputId": "e035f33c-aa5c-426d-ec30-84bcba84d373",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import pandas as pd\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "file = '/content/drive/My Drive/PGML/NLP/tweets.csv'\n",
        "df= pd.read_csv(file, encoding='latin')"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "39pqw0aE5sYe"
      },
      "source": [
        "### Drop null values\n",
        "- drop all the rows with null values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BF_69oyI5sYf"
      },
      "source": [
        "df.dropna(inplace=True)\n"
      ],
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0bm4bDiy5sYg"
      },
      "source": [
        "### Print the dataframe\n",
        "- print initial 5 rows of the data\n",
        "- use df.head()"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "ceSlvAVa5sYh",
        "outputId": "14d17e6f-af7d-400d-b9c3-bcfeaf5c3abe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_text</th>\n",
              "      <th>emotion_in_tweet_is_directed_at</th>\n",
              "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>.@wesley83 I have a 3G iPhone. After 3 hrs twe...</td>\n",
              "      <td>iPhone</td>\n",
              "      <td>Negative emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@jessedee Know about @fludapp ? Awesome iPad/i...</td>\n",
              "      <td>iPad or iPhone App</td>\n",
              "      <td>Positive emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@swonderlin Can not wait for #iPad 2 also. The...</td>\n",
              "      <td>iPad</td>\n",
              "      <td>Positive emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@sxsw I hope this year's festival isn't as cra...</td>\n",
              "      <td>iPad or iPhone App</td>\n",
              "      <td>Negative emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@sxtxstate great stuff on Fri #SXSW: Marissa M...</td>\n",
              "      <td>Google</td>\n",
              "      <td>Positive emotion</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          tweet_text  ... is_there_an_emotion_directed_at_a_brand_or_product\n",
              "0  .@wesley83 I have a 3G iPhone. After 3 hrs twe...  ...                                   Negative emotion\n",
              "1  @jessedee Know about @fludapp ? Awesome iPad/i...  ...                                   Positive emotion\n",
              "2  @swonderlin Can not wait for #iPad 2 also. The...  ...                                   Positive emotion\n",
              "3  @sxsw I hope this year's festival isn't as cra...  ...                                   Negative emotion\n",
              "4  @sxtxstate great stuff on Fri #SXSW: Marissa M...  ...                                   Positive emotion\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jcWfPVqG5sYi"
      },
      "source": [
        "## Question 2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBbAeip_5sYj"
      },
      "source": [
        "### Preprocess data\n",
        "- convert all text to lowercase - use .lower()\n",
        "- select only numbers, alphabets, and #+_ from text - use re.sub()\n",
        "- strip all the text - use .strip()\n",
        "    - this is for removing extra spaces"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PE4Bn_YT5sYj"
      },
      "source": [
        "import re\n",
        "df = df.applymap(lambda s: s.lower())\n",
        "df = df.applymap(lambda s: re.sub('[^0-9a-z #+_]','',s))\n",
        "df = df.applymap(lambda s: s.strip())\n"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QlMvbtrK5sYl"
      },
      "source": [
        "print dataframe"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "afocjaUn5sYm",
        "outputId": "552794a6-e7ed-4b10-e31c-ae3cff0b39e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_text</th>\n",
              "      <th>emotion_in_tweet_is_directed_at</th>\n",
              "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>wesley83 i have a 3g iphone after 3 hrs tweeti...</td>\n",
              "      <td>iphone</td>\n",
              "      <td>negative emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>jessedee know about fludapp  awesome ipadiphon...</td>\n",
              "      <td>ipad or iphone app</td>\n",
              "      <td>positive emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>swonderlin can not wait for #ipad 2 also they ...</td>\n",
              "      <td>ipad</td>\n",
              "      <td>positive emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sxsw i hope this years festival isnt as crashy...</td>\n",
              "      <td>ipad or iphone app</td>\n",
              "      <td>negative emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>sxtxstate great stuff on fri #sxsw marissa may...</td>\n",
              "      <td>google</td>\n",
              "      <td>positive emotion</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          tweet_text  ... is_there_an_emotion_directed_at_a_brand_or_product\n",
              "0  wesley83 i have a 3g iphone after 3 hrs tweeti...  ...                                   negative emotion\n",
              "1  jessedee know about fludapp  awesome ipadiphon...  ...                                   positive emotion\n",
              "2  swonderlin can not wait for #ipad 2 also they ...  ...                                   positive emotion\n",
              "3  sxsw i hope this years festival isnt as crashy...  ...                                   negative emotion\n",
              "4  sxtxstate great stuff on fri #sxsw marissa may...  ...                                   positive emotion\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcTUnvtg5sYn"
      },
      "source": [
        "## Question 3"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4gnaeSXZ5sYo"
      },
      "source": [
        "### Preprocess data\n",
        "- in column \"is_there_an_emotion_directed_at_a_brand_or_product\"\n",
        "    - select only those rows where value equal to \"positive emotion\" or \"negative emotion\"\n",
        "- find the value counts of \"positive emotion\" and \"negative emotion\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nLewJh_35sYp"
      },
      "source": [
        "df=df[(df['is_there_an_emotion_directed_at_a_brand_or_product']=='positive emotion') | (df['is_there_an_emotion_directed_at_a_brand_or_product']=='negative emotion')]"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3VFYB4eh5sYr",
        "outputId": "9046b273-a42c-4240-aad3-27a27ef053ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "df.is_there_an_emotion_directed_at_a_brand_or_product.value_counts()"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "positive emotion    2672\n",
              "negative emotion     519\n",
              "Name: is_there_an_emotion_directed_at_a_brand_or_product, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6icGcVTE5sYz"
      },
      "source": [
        "## Question 4"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rg0rSepj5sYz"
      },
      "source": [
        "### Encode labels\n",
        "- in column \"is_there_an_emotion_directed_at_a_brand_or_product\"\n",
        "    - change \"positive emotion\" to 1\n",
        "    - change \"negative emotion\" to 0\n",
        "- use map function to replace values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YftKwFv7H0N9"
      },
      "source": [
        "df[\"is_there_an_emotion_directed_at_a_brand_or_product\"] = df[\"is_there_an_emotion_directed_at_a_brand_or_product\"].apply(lambda x: 1 if x== 'positive emotion' else 0)"
      ],
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HLZL34IH31Z8",
        "outputId": "df37cd8e-2ebb-44a1-94eb-ed415eb7c56e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "df.head()"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>tweet_text</th>\n",
              "      <th>emotion_in_tweet_is_directed_at</th>\n",
              "      <th>is_there_an_emotion_directed_at_a_brand_or_product</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>wesley83 i have a 3g iphone after 3 hrs tweeti...</td>\n",
              "      <td>iphone</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>jessedee know about fludapp  awesome ipadiphon...</td>\n",
              "      <td>ipad or iphone app</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>swonderlin can not wait for #ipad 2 also they ...</td>\n",
              "      <td>ipad</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>sxsw i hope this years festival isnt as crashy...</td>\n",
              "      <td>ipad or iphone app</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>sxtxstate great stuff on fri #sxsw marissa may...</td>\n",
              "      <td>google</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                          tweet_text  ... is_there_an_emotion_directed_at_a_brand_or_product\n",
              "0  wesley83 i have a 3g iphone after 3 hrs tweeti...  ...                                                  0\n",
              "1  jessedee know about fludapp  awesome ipadiphon...  ...                                                  1\n",
              "2  swonderlin can not wait for #ipad 2 also they ...  ...                                                  1\n",
              "3  sxsw i hope this years festival isnt as crashy...  ...                                                  0\n",
              "4  sxtxstate great stuff on fri #sxsw marissa may...  ...                                                  1\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sC1qSe3h5sY2"
      },
      "source": [
        "## Question 5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aWlAN_Ts5sY2"
      },
      "source": [
        "### Get feature and label\n",
        "- get column \"tweet_text\" as feature\n",
        "- get column \"is_there_an_emotion_directed_at_a_brand_or_product\" as label"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9A3sOZzR5sY4"
      },
      "source": [
        "X=df['tweet_text']\n",
        "y=df['is_there_an_emotion_directed_at_a_brand_or_product']"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3YErwYLCH0N_"
      },
      "source": [
        "### Create train and test data\n",
        "- use train_test_split to get train and test set\n",
        "- set a random_state\n",
        "- test_size: 0.25"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNkwrGgEH0OA"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size=0.25,random_state=1)\n"
      ],
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vCxXGhU27vsX",
        "outputId": "723c11fa-0c34-4046-aaed-8647b581c74b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 119
        }
      },
      "source": [
        "x_train.head()"
      ],
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "8347    tried installing mention on my iphone but it c...\n",
              "2381    #ipad2 rocks #sxsw mention apple pop up store ...\n",
              "8703    whats your take on ipad mention i really want ...\n",
              "4152    aron pilhofer from the new york times just end...\n",
              "3368    lt guess who won an ipad at the #unsix tweetup...\n",
              "Name: feature, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 76
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMok2IX35sY8"
      },
      "source": [
        "## Question 6"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dSqYjPuT5sY8"
      },
      "source": [
        "### Vectorize data\n",
        "- create document-term matrix\n",
        "- use CountVectorizer()\n",
        "    - ngram_range: (1, 2)\n",
        "    - stop_words: 'english'\n",
        "    - min_df: 2   \n",
        "- do fit_transform on X_train\n",
        "- do transform on X_test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bb9PnnqT5sY8"
      },
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cvect = CountVectorizer(ngram_range=(1,2),stop_words='english',min_df=2)\n",
        "cvect.fit(x_train)\n",
        "X_train = cvect.fit_transform(x_train)\n",
        "X_test = cvect.transform(x_test)"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qanDXve15sY_"
      },
      "source": [
        "## Question 7"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMaRNFkV5sY_"
      },
      "source": [
        "### Select classifier logistic regression\n",
        "- use logistic regression for predicting sentiment of the given tweet\n",
        "- initialize classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GT3dNgB55sZA"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "LR_model = LogisticRegression(solver='lbfgs')"
      ],
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pqQ6_HX35sZD"
      },
      "source": [
        "### Fit the classifer\n",
        "- fit logistic regression classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EIzvnNkq5sZD",
        "outputId": "f7c97d53-81d0-4bae-87d7-9f03984cd915",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        }
      },
      "source": [
        "LR_model.fit(X_train, y_train)"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
              "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
              "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
              "                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,\n",
              "                   warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SZpMsYQF5sZF"
      },
      "source": [
        "## Question 8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KGnQnUww5sZF"
      },
      "source": [
        "### Select classifier naive bayes\n",
        "- use naive bayes for predicting sentiment of the given tweet\n",
        "- initialize classifier\n",
        "- use MultinomialNB"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2AbVYssaH0OE"
      },
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "NB_model = MultinomialNB()\n"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QEaG942m5sZI"
      },
      "source": [
        "### Fit the classifer\n",
        "- fit naive bayes classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rLwRBj1R5sZI",
        "outputId": "34fcc8c8-66d2-4c22-9d12-9e7e373113fd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "NB_model.fit(X_train, y_train)"
      ],
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7mgwYDJ5sZM"
      },
      "source": [
        "## Question 9"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sZkA3tce5sZN"
      },
      "source": [
        "### Make predictions on logistic regression\n",
        "- use your trained logistic regression model to make predictions on X_test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l3f0M1ch5sZO",
        "outputId": "480fac8a-a23b-4ca4-d20d-6b3e7e2c65ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        }
      },
      "source": [
        "y_predict_lr = LR_model.predict(X_test)\n",
        "y_predict_lr"
      ],
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "       1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
              "       1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1,\n",
              "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
              "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0,\n",
              "       1, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lrIxjMUB5sZQ"
      },
      "source": [
        "### Make predictions on naive bayes\n",
        "- use your trained naive bayes model to make predictions on X_test\n",
        "- use a different variable name to store predictions so that they are kept separately"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSQnwyLU5sZQ",
        "outputId": "785a6cbc-db06-4d64-b0b3-cef447354cf0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 646
        }
      },
      "source": [
        "y_predict_nb = NB_model.predict(X_test)\n",
        "y_predict_nb\n"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "       1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0,\n",
              "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1,\n",
              "       1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1,\n",
              "       1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0,\n",
              "       1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0,\n",
              "       1, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rwXQUE7b5sZS"
      },
      "source": [
        "## Question 10"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E6SITIE75sZT"
      },
      "source": [
        "### Calculate accuracy of logistic regression\n",
        "- check accuracy of logistic regression classifer\n",
        "- use sklearn.metrics.accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clv2X0kKH0Ok",
        "outputId": "2b2d8f7c-0ec0-4e94-ee23-e8400c6a093d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "print(accuracy_score(y_test, y_predict_lr))"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8659147869674185\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Fd_Gnd05sZV"
      },
      "source": [
        "### Calculate accuracy of naive bayes\n",
        "- check accuracy of naive bayes classifer\n",
        "- use sklearn.metrics.accuracy_score"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d32uBpHi5sZW",
        "outputId": "5dcc6970-7530-43d4-aece-b614c0b55206",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "\n",
        "print(accuracy_score(y_test, y_predict_nb))"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.8571428571428571\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}